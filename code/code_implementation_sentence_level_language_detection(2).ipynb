{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75512fb-55a4-43bd-95e6-f2bac1510cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lib\n",
    "import pandas as pd\n",
    "import os\n",
    "import fasttext\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ea764c-bc78-4227-8e56-50c658d7034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext.FastText.eprint = lambda x: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff3bd3d4-caf8-483a-ba97-22c1d73ee06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>lang_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>সোমবাৰে , ষ্টেনফ ' ৰ্ড ইউনিভাৰচিটি স্কুল অৱ মে...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>শীৰ্ষ গৱেষকে কয় যে এইটোৱে কেন্সাৰ , যক্ষ্মা , ...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>স্থানীয় সময় ( 0230 utc ) অনুসৰি পুৱা 9 : 30 ...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>পাইলটগৰাকী স্কুৱাড্ৰন লীডাৰ ডিলক্ৰিট পাটাভি বু...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>স্থানীয় সংবাদ মাধ্যমে সঁহাৰি জনাওতে বিমানবন্দৰ...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence           lang_tag\n",
       "0  সোমবাৰে , ষ্টেনফ ' ৰ্ড ইউনিভাৰচিটি স্কুল অৱ মে...  __label__asm_Beng\n",
       "1  শীৰ্ষ গৱেষকে কয় যে এইটোৱে কেন্সাৰ , যক্ষ্মা , ...  __label__asm_Beng\n",
       "2  স্থানীয় সময় ( 0230 utc ) অনুসৰি পুৱা 9 : 30 ...  __label__asm_Beng\n",
       "3  পাইলটগৰাকী স্কুৱাড্ৰন লীডাৰ ডিলক্ৰিট পাটাভি বু...  __label__asm_Beng\n",
       "4  স্থানীয় সংবাদ মাধ্যমে সঁহাৰি জনাওতে বিমানবন্দৰ...  __label__asm_Beng"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provide the path to your CSV file\n",
    "file_path = 'dataset/labeled_lang_data_processed.csv'\n",
    "\n",
    "\n",
    "# Check pandas version\n",
    "version = pd.__version__\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "custom_headers = [\"sentence\",\"lang_tag\"]\n",
    "if version >= '1.3.0':\n",
    "    # Use 'on_bad_lines' for pandas version 1.3.0 and above\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=custom_headers, on_bad_lines='skip')\n",
    "else:\n",
    "    # Use 'error_bad_lines' for older pandas versions\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=custom_headers, error_bad_lines=False)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc6f0b5e-0710-4d49-aa16-b138a00d13f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence', 'lang_tag'], dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8f56627-49ad-4fc7-a6a3-109d9e58986e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017768"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d7496b8-0a16-4323-be41-aae5efcc4df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__asm_Beng' '__label__awa_Deva' '__label__ben_Beng'\n",
      " '__label__bho_Deva' '__label__brx_Deva' '__label__dgo_Deva'\n",
      " '__label__gom_Deva' '__label__guj_Gujr' '__label__hin_Deva'\n",
      " '__label__hne_Deva' '__label__kan_Knda' '__label__kas_Arab'\n",
      " '__label__kas_Deva' '__label__lus_Latn' '__label__mag_Deva'\n",
      " '__label__mai_Deva' '__label__mal_Mlym' '__label__mar_Deva'\n",
      " '__label__mni_Beng' '__label__mni_Mtei' '__label__npi_Deva'\n",
      " '__label__ory_Orya' '__label__pan_Guru' '__label__san_Deva'\n",
      " '__label__sat_Olck' '__label__snd_Arab' '__label__snd_Deva'\n",
      " '__label__tam_Taml' '__label__tel_Telu' '__label__urd_Arab'\n",
      " '__label__en_Latn']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"lang_tag\"].unique())#all diff languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba3a436a-fdd4-4cfd-8f86-5773a6f25e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>lang_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>মই একো বুজা নাই !</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>১৩ খন মেডিকেল কলেজ</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thank you all .</td>\n",
       "      <td>__label__en_Latn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>अन्य विशिष्ठगण ,</td>\n",
       "      <td>__label__hin_Deva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>भाईयों और बहनों ,</td>\n",
       "      <td>__label__hin_Deva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentence           lang_tag\n",
       "0  মই একো বুজা নাই !   __label__asm_Beng\n",
       "1  ১৩ খন মেডিকেল কলেজ  __label__asm_Beng\n",
       "2    thank you all .    __label__en_Latn\n",
       "3   अन्य विशिष्ठगण ,   __label__hin_Deva\n",
       "4  भाईयों और बहनों ,   __label__hin_Deva"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Filter sentences with < 20 characters\n",
    "filtered_df = df[\n",
    "    (df['sentence'].str.len() < 20) & \n",
    "    (df['sentence'].str.len()  > 15)\n",
    "]\n",
    "\n",
    "# Group by `lang_tag` and take required counts\n",
    "output = pd.concat([\n",
    "    filtered_df[filtered_df['lang_tag'] == '__label__asm_Beng'].head(2),\n",
    "    filtered_df[filtered_df['lang_tag'] == '__label__en_Latn'].head(1),\n",
    "    filtered_df[filtered_df['lang_tag'] == '__label__hin_Deva'].head(2)\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# Use `.head()` to show the result (limit to first 5 rows if necessary)\n",
    "output.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1393d2c-cfde-4bba-9f93-51db4a6e0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x in df['sentence']:\n",
    "    if x == \"भाईयों और बहनों ,\":\n",
    "        print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4677b7c2-a23f-4a40-b3c5-a158c11f34b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12961    thawhtanni khan , stanford university school o...\n",
       "12962    research lama sulsutu te chuan he thil hian ca...\n",
       "12963    jas 39c grispen chu dar 9 : 30 am local time (...\n",
       "12964    a pilot chu an chhui leh naah squadron leader ...\n",
       "12965    a chheh vela chanchinthar lakhawmtute chuan ai...\n",
       "Name: sentance, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result = df[df['lang_tag'] == '__label__lus_Latn']['sentance']\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3dfc7ee-8db0-4c18-aa13-f8760b7425c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset\n",
    "# Split the dataset into training+validation (80%) and testing (20%)\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split training+val(80%) into training(70%) and validation (10%)\n",
    "train_df , val_df = train_test_split(train_val_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82362dd2-3a7a-4db7-ac87-759abbd77964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732792"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eec9df0-5aab-4f02-9d51-01db5237c416",
   "metadata": {},
   "source": [
    "In paper they make e trained separate classifiers for\n",
    "native script (IndicLID-FTN) and roman script\n",
    "(IndicLID-FTR). but in our data the only the __label__lus_Latn which is a roman script lang tag, hence results differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b27186b4-5bfc-49dd-8bf3-78ffc8356189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fast linear classifier\n",
    "#wordNgrams = \n",
    "#save df in file for fasttext\n",
    "# Prepare the text data in FastText format\n",
    "# Ensure that labels are prefixed with \"__label__\"\n",
    "def train_model(model_path, dim):\n",
    "    i = 0\n",
    "    with open('training_data.txt', 'w') as f:\n",
    "        for index, row in train_df.iterrows():\n",
    "            label = f\"__label__{row[custom_headers[1]]}\"\n",
    "            text = row[custom_headers[0]]\n",
    "            f.write(f\"{label} {text}\\n\")\n",
    "            if i % 100000 == 0:\n",
    "                print(f\"...running {i}\")\n",
    "            i = i + 1\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Train the FastText model\n",
    "    model = fasttext.train_supervised(\n",
    "                        input = 'training_data.txt', \n",
    "                        loss = 'hs',\n",
    "                        verbose = 1,\n",
    "                        dim = dim,\n",
    "                        autotuneValidationFile = 'validation_data.txt', \n",
    "                        autotuneDuration = 14400*3)#epoch not used since 1017768 sample\n",
    "    training_time = time.time() - start_time\n",
    "    model.save_model(model_path)\n",
    "    return model, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4a46286-dad2-44e9-83c0-08def58bbe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions to test\n",
    "dimensions = [8]#[4 , 8, 16]#, 32, 64, 128, 256, 512, 1024]\n",
    "results = {'dim': [], 'precision': [], 'recall': [], 'f1': [], 'accuracy': [], 'throughput': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f70102f-c988-4e8e-91f0-dc2b10eae46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_custom(model, dim, training_time = 1):\n",
    "    # Evaluate on the test set\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    print(len(test_df))\n",
    "    \n",
    "    for index, row in test_df.iterrows():\n",
    "        label = row[custom_headers[1]]\n",
    "        text = row[custom_headers[0]]\n",
    "        #print(label + \" \" + model.predict(text)[0][0].replace(\"__label__\", \"\"))\n",
    "        y_true.append(label.replace(\"__label__\", \"\"))\n",
    "        y_pred.append(model.predict(text)[0][0].replace(\"__label__\", \"\"))  # Clean label\n",
    "\n",
    "    print(set(y_true))\n",
    "    print(set(y_pred))\n",
    "    #print(y_true)\n",
    "    #print(y_pred)\n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate throughput\n",
    "    throughput = len(test_df) / training_time  # Records per second\n",
    "    \n",
    "    # Store results\n",
    "    results['dim'].append(dim)\n",
    "    results['precision'].append(precision)\n",
    "    results['recall'].append(recall)\n",
    "    results['f1'].append(f1)\n",
    "    results['accuracy'].append(accuracy)\n",
    "    results['throughput'].append(throughput)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e9859cb-783a-49b5-a209-28941b54aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_train_model(model_path, dim):\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Loading saved model...\")\n",
    "        model = fasttext.load_model(model_path)\n",
    "        test_model_custom(model, dim,1)\n",
    "    else:\n",
    "        print(\"No saved model found. Training a new model...\")\n",
    "        model, training_time = train_model(model_path, dim)\n",
    "        test_model_custom(model, dim, training_time)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a48614e-66bc-42f7-870e-0a761f67c736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Loading saved model...\n",
      "101777\n",
      "{'guj_Gujr', 'mni_Mtei', 'mag_Deva', 'lus_Latn', 'mni_Beng', 'kas_Deva', 'bho_Deva', 'awa_Deva', 'snd_Deva', 'npi_Deva', 'urd_Arab', 'mar_Deva', 'dgo_Deva', 'brx_Deva', 'kan_Knda', 'mai_Deva', 'en_Latn', 'mal_Mlym', 'hin_Deva', 'hne_Deva', 'ben_Beng', 'tel_Telu', 'pan_Guru', 'ory_Orya', 'snd_Arab', 'sat_Olck', 'san_Deva', 'gom_Deva', 'tam_Taml', 'asm_Beng', 'kas_Arab'}\n",
      "{'guj_Gujr', 'mni_Mtei', 'mag_Deva', 'lus_Latn', 'mni_Beng', 'kas_Deva', 'bho_Deva', 'awa_Deva', 'snd_Deva', 'npi_Deva', 'urd_Arab', 'mar_Deva', 'dgo_Deva', 'brx_Deva', 'kan_Knda', 'mai_Deva', 'en_Latn', 'mal_Mlym', 'hin_Deva', 'hne_Deva', 'ben_Beng', 'tel_Telu', 'pan_Guru', 'ory_Orya', 'snd_Arab', 'sat_Olck', 'san_Deva', 'gom_Deva', 'tam_Taml', 'asm_Beng', 'kas_Arab'}\n",
      "{'dim': [8], 'precision': [0.9919234060221254], 'recall': [0.991825265040235], 'f1': [0.9918204617305368], 'accuracy': [0.991825265040235], 'throughput': [101777.0]}\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./model/bhasha_abhijanan_fasttext_model\"\n",
    "# Load or train the model\n",
    "for dim in dimensions:\n",
    "    print(dim)\n",
    "    model_path_new = model_path + \"dim_\" + str(dim) + \".bin\"\n",
    "    IndicLID = load_or_train_model(model_path_new, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "474a2e8a-01fc-4325-af06-27429710d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the text data in FastText format\n",
    "# Ensure that labels are prefixed with \"__label__\"\n",
    "with open('validation_data.txt', 'w') as f:\n",
    "    for index, row in val_df.iterrows():\n",
    "        label = f\"__label__{row[custom_headers[1]]}\"\n",
    "        text = row[custom_headers[0]]\n",
    "        f.write(f\"{label} {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fd99411-cadc-4a91-ae9c-8476dcd9b65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40711, 0.991746702365454, 0.991746702365454)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IndicLID.test('validation_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dacc42c7-8d4c-4c84-8747-5ce6349e4189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dim': [8],\n",
       " 'precision': [0.9919234060221254],\n",
       " 'recall': [0.991825265040235],\n",
       " 'f1': [0.9918204617305368],\n",
       " 'accuracy': [0.991825265040235],\n",
       " 'throughput': [101777.0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d338fbd1-58f2-49ec-981e-c59febe87946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results():\n",
    "    # Convert results to DataFrame for easy plotting\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Plotting results\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.plot(results_df['dim'], results_df['precision'], marker='o')\n",
    "    plt.title('Precision vs Dimension')\n",
    "    plt.xlabel('Dimension')\n",
    "    plt.ylabel('Precision')\n",
    "    \n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.plot(results_df['dim'], results_df['recall'], marker='o', color='orange')\n",
    "    plt.title('Recall vs Dimension')\n",
    "    plt.xlabel('Dimension')\n",
    "    plt.ylabel('Recall')\n",
    "    \n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.plot(results_df['dim'], results_df['f1'], marker='o', color='green')\n",
    "    plt.title('F1 Score vs Dimension')\n",
    "    plt.xlabel('Dimension')\n",
    "    plt.ylabel('F1 Score')\n",
    "    \n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.plot(results_df['dim'], results_df['accuracy'], marker='o', color='red')\n",
    "    plt.title('Accuracy vs Dimension')\n",
    "    plt.xlabel('Dimension')\n",
    "    plt.ylabel('Accuracy')\n",
    "    \n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.plot(results_df['dim'], results_df['throughput'], marker='o', color='purple')\n",
    "    plt.title('Throughput vs Dimension')\n",
    "    plt.xlabel('Dimension')\n",
    "    plt.ylabel('Throughput (records/sec)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50eacb6b-4005-434a-9cac-abbda7496d2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dim'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshow_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m, in \u001b[0;36mshow_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m], marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision vs Dimension\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDimension\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/py3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dim'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e108c2d6-0fcc-4fbd-8535-f37a5dc3a5b7",
   "metadata": {},
   "source": [
    "# Pretrained LM-based classifier\n",
    "used IndicBERT-based classifier as the LM-based classifier (hence-forth referred to as IndicLID-BERT) since it was amongst the best-performing romanized text classifiers and had maximum language coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2499d128-5935-461f-9914-efaf210cf858",
   "metadata": {},
   "source": [
    "## froze all the layers except for the last softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcf1ed88-6b88-4cf5-adbd-147c2448cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import random\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import transformers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70c0b45e-19c6-49cb-ba02-9253caccaf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh1003/anaconda3/envs/py3.8/lib/python3.8/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32142c82-0871-49fa-92e4-ce6591a33184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/IndicBERTv2-MLM-only and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(250000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=22, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# IndicBERT-MLM-only\n",
    "\n",
    "classes = 22\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBERTv2-MLM-only\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ai4bharat/IndicBERTv2-MLM-only\", num_labels=classes)\n",
    "\n",
    "model.to(device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce1c9c42-f682-402d-acf3-bf21ca58e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load the model\n",
    "model_path = \"./model/bhasha_abhijanan_IndicBert_based_classifier_model\"\n",
    "model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6febfd13-3cc6-44e9-8218-ffd1a314bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze layers\n",
    "for layer in model.bert.encoder.layer:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ce718a0-d978-4d44-9863-579d8c3ec55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/AI4Bharat/IndicLID/blob/master/final_runs_train/roman_model/finetuning/IndicBERT/freezed_bert_all_layer/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81bc5e2c-a6af-421e-b224-fcf914962b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_name = {\n",
    "    'Deva': 'Devanagari',\n",
    "    'Beng': 'Bengali',\n",
    "    'Gujr': 'Gujarati',\n",
    "    'Taml': 'Tamil',\n",
    "    'Arab': 'Arabic',\n",
    "    'Latn': 'Latin',\n",
    "    'Orya': 'Oriya',\n",
    "    'Olck': 'Ol Chiki',\n",
    "    'Knda': 'Kannada',\n",
    "    'Mlym': 'Malayalam',\n",
    "    'Mtei': 'Meetei Mayek',\n",
    "    'Guru': 'Gurmukhi',\n",
    "    'Telu': 'Telugu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80d90211-b395-4a85-9cfb-4f49be29d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicode_ranges = {\n",
    "    'Deva': (0x0900, 0x097F),\n",
    "    'Beng': (0x0980, 0x09FF),\n",
    "    'Gujr': (0x0A80, 0x0AFF),\n",
    "    'Taml': (0x0B80, 0x0BFF),\n",
    "    'Arab': (0x0600, 0x06FF),\n",
    "    'Latn': [(0x0000, 0x007F), (0x1E00, 0x1EFF)],\n",
    "    'Orya': (0x0B00, 0x0B7F),\n",
    "    'Olck': (0x1C50, 0x1C7F),\n",
    "    'Knda': (0x0C80, 0x0CFF),\n",
    "    'Mlym': (0x0D00, 0x0D7F),\n",
    "    'Mtei': (0xABC0, 0xABFF),\n",
    "    'Guru': (0x0A00, 0x0A7F),\n",
    "    'Telu': (0x0C00, 0x0C7F)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "547d9095-7879-4e67-a846-69a23711010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_language = {\n",
    "    'asm': 'Assamese',\n",
    "    'awa': 'Awadhi',\n",
    "    'ben': 'Bengali',\n",
    "    'bho': 'Bhojpuri',\n",
    "    'brx': 'Bodo',\n",
    "    'dgo': 'Dogri',\n",
    "    'en': 'English',\n",
    "    'gom': 'Konkani',\n",
    "    'guj': 'Gujarati',\n",
    "    'hin': 'Hindi',\n",
    "    'hne': 'Chhattisgarhi',\n",
    "    'kan': 'Kannada',\n",
    "    'kas': 'Kashmiri',\n",
    "    'lus': 'Mizo',\n",
    "    'mag': 'Magahi',\n",
    "    'mai': 'Maithili',\n",
    "    'mal': 'Malayalam',\n",
    "    'mar': 'Marathi',\n",
    "    'mni': 'Manipuri',\n",
    "    'npi': 'Nepali',\n",
    "    'ory': 'Odia',\n",
    "    'pan': 'Punjabi',\n",
    "    'san': 'Sanskrit',\n",
    "    'sat': 'Santali',\n",
    "    'snd': 'Sindhi',\n",
    "    'tam': 'Tamil',\n",
    "    'tel': 'Telugu',\n",
    "    'urd': 'Urdu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09a3e807-746c-4ed6-b2e3-1c75198ce55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                label       language        script  single_script  \\\n",
      "0   __label__asm_Beng       Assamese       Bengali          10540   \n",
      "1   __label__awa_Deva         Awadhi    Devanagari            962   \n",
      "2   __label__ben_Beng        Bengali       Bengali          30103   \n",
      "3   __label__bho_Deva       Bhojpuri    Devanagari            864   \n",
      "4   __label__brx_Deva           Bodo    Devanagari            984   \n",
      "5   __label__dgo_Deva          Dogri    Devanagari            963   \n",
      "6    __label__en_Latn        English         Latin          56788   \n",
      "7   __label__gom_Deva        Konkani    Devanagari            976   \n",
      "8   __label__guj_Gujr       Gujarati      Gujarati          49717   \n",
      "9   __label__hin_Deva          Hindi    Devanagari          54837   \n",
      "10  __label__hne_Deva  Chhattisgarhi    Devanagari            906   \n",
      "11  __label__kan_Knda        Kannada       Kannada          35303   \n",
      "12  __label__kas_Arab       Kashmiri        Arabic            929   \n",
      "13  __label__kas_Deva       Kashmiri    Devanagari            718   \n",
      "14  __label__lus_Latn           Mizo         Latin            997   \n",
      "15  __label__mag_Deva         Magahi    Devanagari            985   \n",
      "16  __label__mai_Deva       Maithili    Devanagari            924   \n",
      "17  __label__mal_Mlym      Malayalam     Malayalam          34521   \n",
      "18  __label__mar_Deva        Marathi    Devanagari          36780   \n",
      "19  __label__mni_Beng       Manipuri       Bengali           8224   \n",
      "20  __label__mni_Mtei       Manipuri  Meetei Mayek            993   \n",
      "21  __label__npi_Deva         Nepali    Devanagari            904   \n",
      "22  __label__ory_Orya           Odia         Oriya          38076   \n",
      "23  __label__pan_Guru        Punjabi      Gurmukhi          32501   \n",
      "24  __label__san_Deva       Sanskrit    Devanagari            902   \n",
      "25  __label__sat_Olck        Santali      Ol Chiki            885   \n",
      "26  __label__snd_Arab         Sindhi        Arabic            915   \n",
      "27  __label__snd_Deva         Sindhi    Devanagari            989   \n",
      "28  __label__tam_Taml          Tamil         Tamil          39312   \n",
      "29  __label__tel_Telu         Telugu        Telugu          40364   \n",
      "30  __label__urd_Arab           Urdu        Arabic          12057   \n",
      "\n",
      "    multi_script  \n",
      "0            189  \n",
      "1             35  \n",
      "2            478  \n",
      "3            133  \n",
      "4             13  \n",
      "5             34  \n",
      "6             43  \n",
      "7             21  \n",
      "8           1124  \n",
      "9           2991  \n",
      "10            91  \n",
      "11           926  \n",
      "12            68  \n",
      "13           279  \n",
      "14             0  \n",
      "15            12  \n",
      "16            73  \n",
      "17           145  \n",
      "18           348  \n",
      "19           192  \n",
      "20             4  \n",
      "21            93  \n",
      "22          1270  \n",
      "23          2891  \n",
      "24            95  \n",
      "25           112  \n",
      "26            82  \n",
      "27             8  \n",
      "28          1211  \n",
      "29           897  \n",
      "30           107  \n"
     ]
    }
   ],
   "source": [
    "# Updated function to check if a character belongs to a specific script based on unicode_ranges\n",
    "def get_unicode_script(char):\n",
    "    \"\"\"\n",
    "    Returns the script category for a given character based on unicode_ranges.\n",
    "    \"\"\"\n",
    "    code = ord(char)\n",
    "    for script, range_or_ranges in unicode_ranges.items():\n",
    "        if isinstance(range_or_ranges, list):  # For scripts with multiple ranges\n",
    "            for start, end in range_or_ranges:\n",
    "                if start <= code <= end:\n",
    "                    return script\n",
    "        elif range_or_ranges[0] <= code <= range_or_ranges[1]:\n",
    "            return script\n",
    "    return None\n",
    "\n",
    "# Update the results to identify each label's counts of single and multi-script entries\n",
    "results = []\n",
    "# Define helper functions for script analysis based on Unicode\n",
    "def is_single_script(text):\n",
    "    \"\"\"\n",
    "    Checks if the text has only one script based on Unicode blocks.\n",
    "    \"\"\"\n",
    "    scripts = set()\n",
    "    for char in text:\n",
    "        if char.isalpha():  # Only consider alphabetic characters\n",
    "            script = get_unicode_script(char)\n",
    "            if script:\n",
    "                scripts.add(script)\n",
    "            if len(scripts) > 1:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Function to extract language and script from label\n",
    "def extract_language_and_script(label):\n",
    "    \"\"\"\n",
    "    Extracts language and script names from the label based on known codes.\n",
    "    \"\"\"\n",
    "    parts = label.split('_')\n",
    "    lang_code = parts[-2]  # Language code is in the middle\n",
    "    language_name = label_to_language.get(lang_code.lower(), 'Unknown')\n",
    "    script_code = parts[-1]  # Script code is at the end\n",
    "\n",
    "    # Map script code to full name\n",
    "    script_name = code_to_name.get(script_code, 'Unknown')\n",
    "    #language_name = lang_code.upper()  # Assuming language names can be derived from code (e.g., 'hin' -> 'HIN')\n",
    "    \n",
    "    return language_name, script_name\n",
    "\n",
    "# Update results creation to include full language and script names\n",
    "results = []\n",
    "\n",
    "for label, group in df.groupby('lang_tag'):\n",
    "    language, script = extract_language_and_script(label)\n",
    "    single_script_count = group['sentance'].apply(is_single_script).sum()\n",
    "    multi_script_count = len(group) - single_script_count\n",
    "    results.append({\n",
    "        'label': label,\n",
    "        'language': language,\n",
    "        'script': script,\n",
    "        'single_script': single_script_count,\n",
    "        'multi_script': multi_script_count\n",
    "    })\n",
    "\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "summary_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the updated summary to user\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffd6bad9-4429-4126-8f0c-4bae3721faec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                label       language        script  single_script  \\\n",
      "1   __label__awa_Deva         Awadhi    Devanagari            962   \n",
      "3   __label__bho_Deva       Bhojpuri    Devanagari            864   \n",
      "4   __label__brx_Deva           Bodo    Devanagari            984   \n",
      "10  __label__hne_Deva  Chhattisgarhi    Devanagari            906   \n",
      "5   __label__dgo_Deva          Dogri    Devanagari            963   \n",
      "9   __label__hin_Deva          Hindi    Devanagari          54837   \n",
      "13  __label__kas_Deva       Kashmiri    Devanagari            718   \n",
      "7   __label__gom_Deva        Konkani    Devanagari            976   \n",
      "15  __label__mag_Deva         Magahi    Devanagari            985   \n",
      "16  __label__mai_Deva       Maithili    Devanagari            924   \n",
      "18  __label__mar_Deva        Marathi    Devanagari          36780   \n",
      "21  __label__npi_Deva         Nepali    Devanagari            904   \n",
      "24  __label__san_Deva       Sanskrit    Devanagari            902   \n",
      "27  __label__snd_Deva         Sindhi    Devanagari            989   \n",
      "12  __label__kas_Arab       Kashmiri        Arabic            929   \n",
      "26  __label__snd_Arab         Sindhi        Arabic            915   \n",
      "30  __label__urd_Arab           Urdu        Arabic          12057   \n",
      "6    __label__en_Latn        English         Latin          56788   \n",
      "14  __label__lus_Latn           Mizo         Latin            997   \n",
      "0   __label__asm_Beng       Assamese       Bengali          10540   \n",
      "2   __label__ben_Beng        Bengali       Bengali          30103   \n",
      "8   __label__guj_Gujr       Gujarati      Gujarati          49717   \n",
      "11  __label__kan_Knda        Kannada       Kannada          35303   \n",
      "17  __label__mal_Mlym      Malayalam     Malayalam          34521   \n",
      "19  __label__mni_Beng       Manipuri       Bengali           8224   \n",
      "20  __label__mni_Mtei       Manipuri  Meetei Mayek            993   \n",
      "22  __label__ory_Orya           Odia         Oriya          38076   \n",
      "23  __label__pan_Guru        Punjabi      Gurmukhi          32501   \n",
      "25  __label__sat_Olck        Santali      Ol Chiki            885   \n",
      "28  __label__tam_Taml          Tamil         Tamil          39312   \n",
      "29  __label__tel_Telu         Telugu        Telugu          40364   \n",
      "\n",
      "    multi_script  \n",
      "1             35  \n",
      "3            133  \n",
      "4             13  \n",
      "10            91  \n",
      "5             34  \n",
      "9           2991  \n",
      "13           279  \n",
      "7             21  \n",
      "15            12  \n",
      "16            73  \n",
      "18           348  \n",
      "21            93  \n",
      "24            95  \n",
      "27             8  \n",
      "12            68  \n",
      "26            82  \n",
      "30           107  \n",
      "6             43  \n",
      "14             0  \n",
      "0            189  \n",
      "2            478  \n",
      "8           1124  \n",
      "11           926  \n",
      "17           145  \n",
      "19           192  \n",
      "20             4  \n",
      "22          1270  \n",
      "23          2891  \n",
      "25           112  \n",
      "28          1211  \n",
      "29           897  \n"
     ]
    }
   ],
   "source": [
    "# Define the preferred script order\n",
    "script_order = ['Devanagari', 'Arabic', 'Latin']\n",
    "\n",
    "# Add a helper column for sorting based on the script order\n",
    "summary_df['script_order'] = summary_df['script'].apply(lambda x: script_order.index(x) if x in script_order else len(script_order))\n",
    "\n",
    "# Sort the DataFrame first by the custom script order and then by the language for consistency\n",
    "sorted_summary_df = summary_df.sort_values(by=['script_order', 'language']).drop(columns=['script_order'])\n",
    "\n",
    "# Display the sorted summary to user\n",
    "print(sorted_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ef6a27c-f8da-4a6d-a6cb-8943102d48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_script(text):\n",
    "    # Initialize counts for each script\n",
    "    script_count = {script: 0 for script in unicode_ranges}\n",
    "    \n",
    "    # Check each character in text\n",
    "    for char in text:\n",
    "        char_code = ord(char)\n",
    "        for script, ranges in unicode_ranges.items():\n",
    "            # Handle multiple ranges (like Latin)\n",
    "            if isinstance(ranges, list):\n",
    "                if any(start <= char_code <= end for start, end in ranges):\n",
    "                    script_count[script] += 1\n",
    "            else:\n",
    "                start, end = ranges\n",
    "                if start <= char_code <= end:\n",
    "                    script_count[script] += 1\n",
    "    \n",
    "    # Identify the script with the most characters in the sentence\n",
    "    detected_script = max(script_count, key=script_count.get)\n",
    "    return detected_script if script_count[detected_script] > 0 else \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee4cea24-bdce-4578-b7f6-209b78d7888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the detection function on the DataFrame and compare results\n",
    "df[\"detected_script\"] = df[\"sentance\"].apply(detect_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "006f0557-9555-42d0-8854-5cd30ed618ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentance</th>\n",
       "      <th>lang_tag</th>\n",
       "      <th>detected_script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>সোমবাৰে , ষ্টেনফ ' ৰ্ড ইউনিভাৰচিটি স্কুল অৱ মে...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "      <td>Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>শীৰ্ষ গৱেষকে কয় যে এইটোৱে কেন্সাৰ , যক্ষ্মা , ...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "      <td>Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>স্থানীয় সময় ( 0230 utc ) অনুসৰি পুৱা 9 : 30 ...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "      <td>Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>পাইলটগৰাকী স্কুৱাড্ৰন লীডাৰ ডিলক্ৰিট পাটাভি বু...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "      <td>Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>স্থানীয় সংবাদ মাধ্যমে সঁহাৰি জনাওতে বিমানবন্দৰ...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "      <td>Beng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentance           lang_tag  \\\n",
       "0  সোমবাৰে , ষ্টেনফ ' ৰ্ড ইউনিভাৰচিটি স্কুল অৱ মে...  __label__asm_Beng   \n",
       "1  শীৰ্ষ গৱেষকে কয় যে এইটোৱে কেন্সাৰ , যক্ষ্মা , ...  __label__asm_Beng   \n",
       "2  স্থানীয় সময় ( 0230 utc ) অনুসৰি পুৱা 9 : 30 ...  __label__asm_Beng   \n",
       "3  পাইলটগৰাকী স্কুৱাড্ৰন লীডাৰ ডিলক্ৰিট পাটাভি বু...  __label__asm_Beng   \n",
       "4  স্থানীয় সংবাদ মাধ্যমে সঁহাৰি জনাওতে বিমানবন্দৰ...  __label__asm_Beng   \n",
       "\n",
       "  detected_script  \n",
       "0            Beng  \n",
       "1            Beng  \n",
       "2            Beng  \n",
       "3            Beng  \n",
       "4            Beng  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31e5ca29-2260-4a13-a18f-50d338f0d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"expected_script\"] = df[\"lang_tag\"].str.split('_').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9460dc53-b263-450f-8a40-82b44e1148af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentance</th>\n",
       "      <th>lang_tag</th>\n",
       "      <th>detected_script</th>\n",
       "      <th>expected_script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>সোমবাৰে , ষ্টেনফ ' ৰ্ড ইউনিভাৰচিটি স্কুল অৱ মে...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "      <td>Beng</td>\n",
       "      <td>Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>শীৰ্ষ গৱেষকে কয় যে এইটোৱে কেন্সাৰ , যক্ষ্মা , ...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "      <td>Beng</td>\n",
       "      <td>Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>স্থানীয় সময় ( 0230 utc ) অনুসৰি পুৱা 9 : 30 ...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "      <td>Beng</td>\n",
       "      <td>Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>পাইলটগৰাকী স্কুৱাড্ৰন লীডাৰ ডিলক্ৰিট পাটাভি বু...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "      <td>Beng</td>\n",
       "      <td>Beng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>স্থানীয় সংবাদ মাধ্যমে সঁহাৰি জনাওতে বিমানবন্দৰ...</td>\n",
       "      <td>__label__asm_Beng</td>\n",
       "      <td>Beng</td>\n",
       "      <td>Beng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentance           lang_tag  \\\n",
       "0  সোমবাৰে , ষ্টেনফ ' ৰ্ড ইউনিভাৰচিটি স্কুল অৱ মে...  __label__asm_Beng   \n",
       "1  শীৰ্ষ গৱেষকে কয় যে এইটোৱে কেন্সাৰ , যক্ষ্মা , ...  __label__asm_Beng   \n",
       "2  স্থানীয় সময় ( 0230 utc ) অনুসৰি পুৱা 9 : 30 ...  __label__asm_Beng   \n",
       "3  পাইলটগৰাকী স্কুৱাড্ৰন লীডাৰ ডিলক্ৰিট পাটাভি বু...  __label__asm_Beng   \n",
       "4  স্থানীয় সংবাদ মাধ্যমে সঁহাৰি জনাওতে বিমানবন্দৰ...  __label__asm_Beng   \n",
       "\n",
       "  detected_script expected_script  \n",
       "0            Beng            Beng  \n",
       "1            Beng            Beng  \n",
       "2            Beng            Beng  \n",
       "3            Beng            Beng  \n",
       "4            Beng            Beng  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a52606c1-1c62-47b7-abda-8a16e8daae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of script detection: 99.76870956838887%\n",
      "Mismatched rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>pbs शो के दू दर्जन से जादा एम्मी अवार्ड मिलल ब...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>animal liberation अउर royal society for the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9207</th>\n",
       "      <td>&amp; quot ; हमन जम्मों झि बस सदमा म रहेन , &amp; quo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11048</th>\n",
       "      <td>۔hesperonychus elizabethae چھَ dromaeosauridae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11302</th>\n",
       "      <td>ترکیہک diva sezen aksuکۄٚر پٲرفارم اِٹلیکِس te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentance\n",
       "3028   pbs शो के दू दर्जन से जादा एम्मी अवार्ड मिलल ब...\n",
       "3277   animal liberation अउर royal society for the pr...\n",
       "9207    & quot ; हमन जम्मों झि बस सदमा म रहेन , & quo...\n",
       "11048  ۔hesperonychus elizabethae چھَ dromaeosauridae...\n",
       "11302  ترکیہک diva sezen aksuکۄٚر پٲرفارم اِٹلیکِس te..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "correct_matches = (df[\"detected_script\"] == df[\"expected_script\"]).sum()\n",
    "accuracy = correct_matches / len(df) * 100\n",
    "\n",
    "print(f\"Accuracy of script detection: {accuracy}%\")\n",
    "\n",
    "# Filter the DataFrame for mismatches\n",
    "mismatches = df[df[\"detected_script\"] != df[\"expected_script\"]]\n",
    "\n",
    "# Print the mismatched rows\n",
    "print(\"Mismatched rows:\")\n",
    "#print(mismatches[[\"sentance\", \"lang_tag\", \"detected_script\", \"expected_script\"]])\n",
    "mismatches[[\"sentance\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "959e7074-4606-4eb9-a7ef-3ff9bf07c240",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_mixed_script' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(word_scripts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Apply detection function on DataFrame\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mdf_mixed_script\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed_script\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentance\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(detect_mixed_script)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Display sentences with mixed scripts\u001b[39;00m\n\u001b[1;32m     37\u001b[0m mixed_script_sentences \u001b[38;5;241m=\u001b[39m df_mixed_script[df_mixed_script[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed_script\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_mixed_script' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to detect script for each character in a word\n",
    "def detect_word_script(char):\n",
    "    char_code = ord(char)\n",
    "    for script, ranges in unicode_ranges.items():\n",
    "        if isinstance(ranges, list):\n",
    "            if any(start <= char_code <= end for start, end in ranges):\n",
    "                return script\n",
    "        else:\n",
    "            start, end = ranges\n",
    "            if start <= char_code <= end:\n",
    "                return script\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Function to check if a sentence contains words in multiple scripts\n",
    "def detect_mixed_script(sentence):\n",
    "    words = sentence.split()\n",
    "    word_scripts = set()\n",
    "\n",
    "    for word in words:\n",
    "        # Get the dominant script for each word\n",
    "        script_count = {}\n",
    "        for char in word:\n",
    "            script = detect_word_script(char)\n",
    "            if script != \"Unknown\":\n",
    "                script_count[script] = script_count.get(script, 0) + 1\n",
    "        # Get the most common script in the word\n",
    "        if script_count:\n",
    "            dominant_script = max(script_count, key=script_count.get)\n",
    "            word_scripts.add(dominant_script)\n",
    "\n",
    "    return len(word_scripts) > 1\n",
    "\n",
    "# Apply detection function on DataFrame\n",
    "df_mixed_script[\"mixed_script\"] = df[\"sentance\"].apply(detect_mixed_script)\n",
    "\n",
    "# Display sentences with mixed scripts\n",
    "mixed_script_sentences = df_mixed_script[df_mixed_script[\"mixed_script\"] == True]\n",
    "print(\"Sentences with mixed scripts:\")\n",
    "print(mixed_script_sentences[[\"sentance\", \"lang_tag\", \"mixed_script\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50c4259-afa6-4698-8f6d-1a6bd5df748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched_sentences_set = set(mismatches[\"sentance\"])\n",
    "mixed_script_sentences_set = set(mixed_script_sentences[\"sentance\"])\n",
    "# Output results\n",
    "\n",
    "unmatched_sentences = mismatched_sentences_set - mixed_script_sentences_set\n",
    "\n",
    "# Output results\n",
    "if not unmatched_sentences:\n",
    "    print(\"All mismatched sentences are in mixed_script sentences.\")\n",
    "else:\n",
    "    print(\"Some mismatched sentences are not in mixed_script sentences:\")\n",
    "    print(unmatched_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527a35f-233c-49cb-a882-ec15905d2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mixed_script_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d7006-5aa8-499e-a877-6a5e24efc357",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b92607-02d5-475d-b185-11dd3984a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where detected_script matches expected_script\n",
    "df_non_code_mixed = df[df[\"detected_script\"] == df[\"expected_script\"]].reset_index(drop=True)\n",
    "\n",
    "# Check if 'mixed_script' column exists and drop it\n",
    "if 'mixed_script' in df_non_code_mixed.columns:\n",
    "    df_non_code_mixed.drop(columns=['mixed_script'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_non_code_mixed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88659a0c-5f1e-4db9-bab2-d01f6a8e8fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
